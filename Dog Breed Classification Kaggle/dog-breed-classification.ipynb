{"cells":[{"metadata":{"_uuid":"423dc9aa-9548-448c-b857-25fcce97f5ab","_cell_guid":"73475a81-5f68-48ee-97f8-e97b8e811d76","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch # Importing pytorch\nfrom torchvision import models, transforms # To get pretrained deep NNs and various image transforms\nfrom torch.utils.data import Dataset, DataLoader #\nfrom torch import nn, optim # NN module to customize network and optim to get various optimizers\nfrom PIL import Image # to load images\nimport matplotlib.pyplot as plt # to plot images and graphs\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Custom dataset class\nclass DogBreedDataset(Dataset):\n    def __init__(self, training_dir_path, train_df, label2id, transform):\n        self.training_dir_path = training_dir_path\n        self.df = train_df\n        \n        # Calculate weights for each class to pass to Cross Entropy Loss\n        temp = train_df.replace({\"breed\": label2id})\n        cnts_df = temp.groupby(['breed']).count()\n        self.weights = cnts_df.id.values.tolist()\n        total = sum(self.weights)\n        self.weights = list(map(lambda w: (total/w)/100, self.weights))\n        \n        self.label2id = label2id\n        self.transform = transform\n        \n    def __len__(self):\n        # Return size of the dataset\n        return len(self.df.index)\n    \n    def __getitem__(self, idx):\n        # Read image using PIL\n        image = Image.open(os.path.join(self.training_dir_path, self.df.iloc[idx, 0]) + '.jpg')\n        \n        # Extract image's true label from dataframe\n        label = label2id[self.df.iloc[idx, 1]]\n        \n        # Transform image if specified (eg. Resize, Crop, flip, etc)\n        if self.transform:\n            image = self.transform(image)\n        return image, label","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get resnet with pre-trained weights and modify classifier to output N numbers\nmodel = models.resnext50_32x4d(pretrained=True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 120)\ni=0\nfor name, param in model.named_parameters():\n    # print(i, name)\n    if i < 93:\n        param.requires_grad = False\n    else:\n        break\n    i += 1\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Move model to device\nmodel = model.to(device)","execution_count":3,"outputs":[{"output_type":"stream","text":"Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/checkpoints/resnext50_32x4d-7cdf4587.pth\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=100441675.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a0c4db2874949ffa3dd476b11d2961f"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read csv file containing image file names and it's corresponding breed name. Also shuffle after reading\nlabels = pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv').sample(frac=1).reset_index(drop=True)\n\n# Get all unique breed names\nunique_labels = labels.breed.unique()\nunique_labels.sort()\n\n# Make dict to map breed name to a index b.w 0 to N-1\nlabel2id = {}\nfor idx, name in enumerate(unique_labels):\n    label2id[name] = idx\n\ntraining_dir_path = '/kaggle/input/dog-breed-identification/train'\nlabels_path = '/kaggle/input/dog-breed-identification/labels.csv'\n    \ndef get_train_val_loader(labels, label2id, training_dir_path, labels_path, train_frac = 1, batch_size = 32, nb_workers = 4):\n    # Total number of training examples\n    nb_exmpls = len(labels.index)\n    \n    # Split original dataframe to train and validation df\n    split = int(np.floor(train_frac * nb_exmpls))\n    \n    # Shuffle data\n    labels = labels.sample(frac = 1)\n    \n    # Train/Val split\n    train_df = labels.iloc[:split, :]\n    val_df = labels.iloc[split:, :]\n\n    # Transform for train set\n    train_transform = transforms.Compose([transforms.ColorJitter(brightness=0.3, contrast=0.4, saturation=0.4),\n                                        transforms.RandomHorizontalFlip(),\n                                        transforms.RandomVerticalFlip(),\n                                        transforms.RandomAffine(degrees=30, translate=(.2, .2), scale=(0.75, 1.25),\n                                                      shear=[-30, 30, -30, 30]),\n                                        transforms.Resize((224, 224)),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n    # Create dataset class for train set\n    train_dataset = DogBreedDataset(training_dir_path, train_df, label2id, train_transform)\n    \n    # Create train data loader to batch data on the fly to feed the model\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=nb_workers, shuffle=True)\n    \n    if train_frac == 1:\n        return (train_dataset, train_loader)\n    else:\n        # Transform for validation set\n        val_transform = transforms.Compose([transforms.Resize((224, 224)),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n        # Create dataset class for validation set\n        val_dataset = DogBreedDataset(training_dir_path, val_df, label2id, val_transform)\n\n        # Data loader for val set\n        val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=nb_workers, shuffle=True)\n        \n        return (train_dataset, train_loader, val_dataset, val_loader)\n    \nbatch_size = 256\ntrain_dataset, train_loader, val_dataset, val_loader = get_train_val_loader(labels, label2id, training_dir_path, labels_path, batch_size = batch_size, train_frac = 0.8)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for images, targets in train_loader:\n#     for i in range(batch_size):\n#         img = images[i, :, :, :].numpy().transpose((1, 2, 0))\n#         mean = np.array([[[.485, 0.456, 0.406]]])\n#         std = np.array([[[.229, 0.224, 0.225]]])\n#         img = img*std + mean\n#         plt.imshow(img)\n#         plt.title(unique_labels[int(targets[i].item())])\n#         plt.show()\n#     break","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross entropy loss for multiclass classification and Adam optimizer\ncriterion = nn.CrossEntropyLoss(weight = torch.cuda.FloatTensor(train_dataset.weights))\noptimizer = optim.Adam(filter(lambda param: param.requires_grad, model.parameters()))\n\n# Learning rate scheduler to update lr when loss stops improving\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total number of epochs to train for\nn_epochs = 100\n\n# Keep track of max val_acc\nval_acc_max = 0\n\nfor epoch in range(n_epochs):\n    train_loss = 0.0\n    val_loss = 0.0\n    \n    # Set model to train mode\n    model.train()\n    \n    # Iterate through training set by processing batches\n    for data, target in train_loader:\n        # Move data to device\n        data, target = data.to(device), target.to(device)\n        \n        # Zero out previous gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        output = model(data)\n        \n        # Calculate loss\n        loss = criterion(output, target)\n        \n        # Backpropagate to calculate gradients w.r.t. loss\n        loss.backward()\n        \n        # Alter model params\n        optimizer.step()\n        \n        train_loss += loss.item()*data.size(0)\n        \n    # Calculate avg loss over whole training set\n    train_loss = train_loss/len(train_dataset)\n    \n    # Set model to eval mode\n    model.eval()\n    \n    # Turn off gradient calculations for validation task\n    with torch.no_grad():\n        \n        # For calculating val acc\n        total = 0\n        correct = 0\n\n        # Do forward pass through validation data and calculate val_loss\n        for data, target in val_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            _, preds = torch.max(output, dim=1)\n            total += target.size(0)\n            correct += torch.sum(preds == target).cpu().data.item()\n            loss = criterion(output, target)\n            val_loss += loss.item()*data.size(0)\n\n        val_loss = val_loss/len(val_dataset)\n        \n    print('Epoch: {} \\Train Loss: {:.6f} \\t Val Loss: {:.6f} \\t Val Acc: {:.6f}'.format(epoch+1, train_loss, val_loss, correct/total))\n    \n    # Save model if val_acc has increased\n    if (correct/total) > val_acc_max:\n        print('Val Acc increased ({:.6f} --> {:.6f}).  Saving model ...'.format(val_acc_max, correct/total))\n        torch.save(model, 'dog_breed_model.pt')\n        val_acc_max = correct/total\n        \n    scheduler.step(val_loss)","execution_count":7,"outputs":[{"output_type":"stream","text":"Epoch: 1 \\Train Loss: 2.793475 \t Val Loss: 2.107004 \t Val Acc: 0.461125\nVal Acc increased (0.000000 --> 0.461125).  Saving model ...\nEpoch: 2 \\Train Loss: 1.760453 \t Val Loss: 1.865718 \t Val Acc: 0.502200\nVal Acc increased (0.461125 --> 0.502200).  Saving model ...\nEpoch: 3 \\Train Loss: 1.470776 \t Val Loss: 1.547243 \t Val Acc: 0.552567\nVal Acc increased (0.502200 --> 0.552567).  Saving model ...\nEpoch: 4 \\Train Loss: 1.259667 \t Val Loss: 1.462246 \t Val Acc: 0.593154\nVal Acc increased (0.552567 --> 0.593154).  Saving model ...\nEpoch: 5 \\Train Loss: 1.124360 \t Val Loss: 1.444758 \t Val Acc: 0.600489\nVal Acc increased (0.593154 --> 0.600489).  Saving model ...\nEpoch: 6 \\Train Loss: 1.024087 \t Val Loss: 1.393339 \t Val Acc: 0.610758\nVal Acc increased (0.600489 --> 0.610758).  Saving model ...\nEpoch: 7 \\Train Loss: 0.921128 \t Val Loss: 1.405163 \t Val Acc: 0.617604\nVal Acc increased (0.610758 --> 0.617604).  Saving model ...\nEpoch: 8 \\Train Loss: 0.816486 \t Val Loss: 1.430312 \t Val Acc: 0.643032\nVal Acc increased (0.617604 --> 0.643032).  Saving model ...\nEpoch: 9 \\Train Loss: 0.725710 \t Val Loss: 1.396075 \t Val Acc: 0.650367\nVal Acc increased (0.643032 --> 0.650367).  Saving model ...\nEpoch: 10 \\Train Loss: 0.652035 \t Val Loss: 1.494557 \t Val Acc: 0.639609\nEpoch: 11 \\Train Loss: 0.620045 \t Val Loss: 1.519362 \t Val Acc: 0.627384\nEpoch: 12 \\Train Loss: 0.571078 \t Val Loss: 1.564350 \t Val Acc: 0.630318\nEpoch: 13 \\Train Loss: 0.358296 \t Val Loss: 1.135906 \t Val Acc: 0.709535\nVal Acc increased (0.650367 --> 0.709535).  Saving model ...\nEpoch: 14 \\Train Loss: 0.264991 \t Val Loss: 1.115863 \t Val Acc: 0.711980\nVal Acc increased (0.709535 --> 0.711980).  Saving model ...\nEpoch: 15 \\Train Loss: 0.231032 \t Val Loss: 1.106357 \t Val Acc: 0.711002\nEpoch: 16 \\Train Loss: 0.208865 \t Val Loss: 1.112232 \t Val Acc: 0.723716\nVal Acc increased (0.711980 --> 0.723716).  Saving model ...\nEpoch: 17 \\Train Loss: 0.182650 \t Val Loss: 1.112458 \t Val Acc: 0.718337\nEpoch: 18 \\Train Loss: 0.173476 \t Val Loss: 1.124232 \t Val Acc: 0.713447\nEpoch: 19 \\Train Loss: 0.161453 \t Val Loss: 1.140944 \t Val Acc: 0.714425\nEpoch: 20 \\Train Loss: 0.150865 \t Val Loss: 1.137201 \t Val Acc: 0.722249\nEpoch: 21 \\Train Loss: 0.140220 \t Val Loss: 1.150601 \t Val Acc: 0.712958\nEpoch: 22 \\Train Loss: 0.141111 \t Val Loss: 1.150867 \t Val Acc: 0.716870\nEpoch: 23 \\Train Loss: 0.133070 \t Val Loss: 1.142897 \t Val Acc: 0.720782\nEpoch: 24 \\Train Loss: 0.129433 \t Val Loss: 1.142767 \t Val Acc: 0.719804\nEpoch: 25 \\Train Loss: 0.123520 \t Val Loss: 1.142550 \t Val Acc: 0.721271\nEpoch: 26 \\Train Loss: 0.123342 \t Val Loss: 1.152928 \t Val Acc: 0.719315\nEpoch: 27 \\Train Loss: 0.126065 \t Val Loss: 1.144657 \t Val Acc: 0.717359\nEpoch: 28 \\Train Loss: 0.127563 \t Val Loss: 1.141522 \t Val Acc: 0.719804\nEpoch: 29 \\Train Loss: 0.118983 \t Val Loss: 1.144092 \t Val Acc: 0.722738\nEpoch: 30 \\Train Loss: 0.122544 \t Val Loss: 1.142364 \t Val Acc: 0.720782\nEpoch: 31 \\Train Loss: 0.131498 \t Val Loss: 1.140773 \t Val Acc: 0.718826\nEpoch: 32 \\Train Loss: 0.128552 \t Val Loss: 1.144976 \t Val Acc: 0.719315\nEpoch: 33 \\Train Loss: 0.126654 \t Val Loss: 1.144719 \t Val Acc: 0.719804\nEpoch: 34 \\Train Loss: 0.118722 \t Val Loss: 1.142367 \t Val Acc: 0.724694\nVal Acc increased (0.723716 --> 0.724694).  Saving model ...\nEpoch: 35 \\Train Loss: 0.125528 \t Val Loss: 1.141980 \t Val Acc: 0.721271\nEpoch: 36 \\Train Loss: 0.123446 \t Val Loss: 1.142445 \t Val Acc: 0.720782\nEpoch: 37 \\Train Loss: 0.120360 \t Val Loss: 1.141647 \t Val Acc: 0.717848\nEpoch: 38 \\Train Loss: 0.128349 \t Val Loss: 1.145891 \t Val Acc: 0.717359\nEpoch: 39 \\Train Loss: 0.124329 \t Val Loss: 1.146493 \t Val Acc: 0.722249\nEpoch: 40 \\Train Loss: 0.126660 \t Val Loss: 1.146541 \t Val Acc: 0.720782\nEpoch: 41 \\Train Loss: 0.122371 \t Val Loss: 1.146993 \t Val Acc: 0.722738\nEpoch: 42 \\Train Loss: 0.128049 \t Val Loss: 1.148503 \t Val Acc: 0.720782\nEpoch: 43 \\Train Loss: 0.125902 \t Val Loss: 1.140178 \t Val Acc: 0.718337\nEpoch: 44 \\Train Loss: 0.119162 \t Val Loss: 1.142822 \t Val Acc: 0.718337\nEpoch: 45 \\Train Loss: 0.125384 \t Val Loss: 1.142664 \t Val Acc: 0.721760\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-62cc61c415ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Iterate through training set by processing batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Move data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir_path = '/kaggle/input/dog-breed-identification/test'\nfilenames = []\nfor filename in os.listdir(test_dir_path):\n    filenames.append(filename.split('.')[0])\nout = pd.DataFrame(filenames, columns = ['id'])\nout = out.sort_values(by = 'id')\nout = out.reset_index(drop=True)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Custom dataset class\nclass TestDataset(Dataset):\n    def __init__(self, test_dir_path, test_df, transform):\n        self.test_dir_path = test_dir_path\n        self.df = test_df\n        self.transform = transform\n        \n    def __len__(self):\n        # Return size of the dataset\n        return len(self.df.index)\n    \n    def __getitem__(self, idx):\n        # Read image using PIL\n        image = Image.open(os.path.join(self.test_dir_path, self.df.iloc[idx, 0]) + '.jpg')\n        \n        # Transform image if specified (eg. Resize, Crop, flip, etc)\n        if self.transform:\n            image = self.transform(image)\n        return image\n    \ntest_transform = transforms.Compose([transforms.Resize((224, 224)),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    \nbatch_size = 128\ntest_dataset = TestDataset(test_dir_path, out, test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=0)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = '/kaggle/working/dog_breed_model.pt'\n\npreds = np.zeros((batch_size, len(unique_labels)), dtype=np.float32)\n\nsaved_model = torch.load(model_path)\nsaved_model.to(device)\nsaved_model.eval()\n\nwith torch.no_grad():\n    for data in test_loader:\n        data = data.to(device)\n        output = saved_model(data)\n        output = torch.nn.functional.softmax(output, 1)\n        preds = np.vstack((preds, output.detach().cpu().numpy()))\n    preds = preds[batch_size:, :]","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df = pd.DataFrame(data=preds, columns=unique_labels)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([out, preds_df], axis = 1)\nsubmission.to_csv (r'/kaggle/working/submission.csv', index = False, header=True)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}